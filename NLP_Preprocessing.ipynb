{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Preprocessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/derek-shing/NLP/blob/master/NLP_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmxMN6dNFCU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5QhJIeAID-1",
        "colab_type": "text"
      },
      "source": [
        "Steps:\n",
        "1 . Upper/lower case\n",
        "2. Remove noise\n",
        "3. Text Normalization\n",
        "4. Stemming\n",
        "5. Lementization\n",
        "6. Tokenzation\n",
        "7. Remove stop word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNruJtlwIqaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = \"In this exercise, we will take an input sentence with both uppercase and lowercase characters and convert them all into lowercase characters. The following steps will help you with the solution:\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OpntUJTI1XO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2c70cc5c-fbf0-429e-ebb0-e8c28d4e20f2"
      },
      "source": [
        "s.lower()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in this exercise, we will take an input sentence with both uppercase and lowercase characters and convert them all into lowercase characters. the following steps will help you with the solution:'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFBHFfPqJpfY",
        "colab_type": "text"
      },
      "source": [
        "**2. Noise Removal using regular expression.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTOb4sfnJyfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aGQI598JyUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw = ['..sleepy', 'sleepy!!', '#sleepy', '>>>>>sleepy>>>>', '<a>sleepy</a>']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LH_n9Y9KKKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_word(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(\"(<.*?>)\",\"\",text)\n",
        "  text=re.sub(\"(\\W|\\d+)\",\" \",text)\n",
        "  text=text.strip()\n",
        "  #stemmer = PorterStemmer()\n",
        "  #text = stemmer.stem(text)\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR68befJLx2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = [clean_word(i) for i in raw]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbFnZFNtMT_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddcc4d99-b129-438a-c557-ca5d3e8a4360"
      },
      "source": [
        "print(final)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sleepy', 'sleepy', 'sleepy', 'sleepy', 'sleepy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1hKwYrAPBa4",
        "colab_type": "text"
      },
      "source": [
        "**4. Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sogISPhzPU1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7vdPubSPkst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw = \"However, stemming doesn't always provide the desired stem, since it works by chopping off the ends of the words. It's possible for the stemmer to reduce 'troubling' to 'troubl' instead of 'trouble' and this won't really help in problem solving, and so stemming isn't a method that's used too often. When it is used, Porter's stemming algorithm is the most common algorithm for stemming.\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgg0rmgYPzGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = raw.split()\n",
        "word_list = [clean_word(i) for i in words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsjVuc83m3vb",
        "colab_type": "text"
      },
      "source": [
        "**5. Lemmatization**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiUYUQ_Cmn0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "aae4ae91-4f0a-408a-c537-44f56b8eff45"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjSCHr7lnop_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DWeNJa6oOkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final=[lemmatizer.lemmatize(word=i,pos='v') for i in word_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP3zna7JomVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'before':word_list,'lemmatized':final})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc0hKLoZo1Hq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "e8b5f4f5-d10c-4990-f4db-c82eb4229e6c"
      },
      "source": [
        "df[df['before']!=df['lemmatized']]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>before</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stemming</td>\n",
              "      <td>stem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>desired</td>\n",
              "      <td>desire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>works</td>\n",
              "      <td>work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>chopping</td>\n",
              "      <td>chop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ends</td>\n",
              "      <td>end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>words</td>\n",
              "      <td>word</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>troubling</td>\n",
              "      <td>trouble</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>solving</td>\n",
              "      <td>solve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>stemming</td>\n",
              "      <td>stem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>used</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>is</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>used</td>\n",
              "      <td>use</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>stemming</td>\n",
              "      <td>stem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>is</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>stemming</td>\n",
              "      <td>stem</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       before lemmatized\n",
              "1    stemming       stem\n",
              "6     desired     desire\n",
              "10      works       work\n",
              "12   chopping       chop\n",
              "15       ends        end\n",
              "18      words       word\n",
              "26  troubling    trouble\n",
              "39    solving      solve\n",
              "42   stemming       stem\n",
              "47       used        use\n",
              "52         is         be\n",
              "53       used        use\n",
              "55   stemming       stem\n",
              "57         is         be\n",
              "63   stemming       stem"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUBc4RHqqVdR",
        "colab_type": "text"
      },
      "source": [
        "**Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vet0_tr_qe3Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8db24e19-6d1d-46ee-8b4e-60fac1c7f09c"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0eFDUgzqnBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve-TVYgdqxe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = \"hi! my name isn't john.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUdm70Odqyh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token = word_tokenize(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6zN-VbIq3F4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fb8c182-bbda-44ce-ecb4-a8465eb6677d"
      },
      "source": [
        "token"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', '!', 'my', 'name', 'is', \"n't\", 'john', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvO1uJ79uqOP",
        "colab_type": "text"
      },
      "source": [
        "**Remove Stopword**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-kYGeJcu5n6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9a5248db-4fb0-49a6-ce8f-4ed218c5159b"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztkhu5u5vFzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63cf79cf-f54d-4d43-dd9c-b41f95dcf782"
      },
      "source": [
        "len(stop_words)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwDzXrN_uv7G",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usezP6eNuiAQ",
        "colab_type": "text"
      },
      "source": [
        "**Word Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra5a4BL6undn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iGh-4h-vqrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Y40iF9v6fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s1 = \"Ariana Grande is a singer\"\n",
        "\n",
        "s2 = \"She has been a singer for many years\"\n",
        "\n",
        "s3 = \"Ariana is a great singer\"\n",
        "\n",
        "sentences = [word_tokenize(s1), word_tokenize(s2), word_tokenize(s3)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4NcuR5Mv8tV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f461a656-0b28-44ad-94cc-31e6e781d7e6"
      },
      "source": [
        "sentences"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Ariana', 'Grande', 'is', 'a', 'singer'],\n",
              " ['She', 'has', 'been', 'a', 'singer', 'for', 'many', 'years'],\n",
              " ['Ariana', 'is', 'a', 'great', 'singer']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMNxsh3CwMhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Word2Vec(sentences, min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gtYSihxwT2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34b1f7f2-4ff2-48a7-f403-64e276206810"
      },
      "source": [
        "print('this is the summary of the model: ')\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is the summary of the model: \n",
            "Word2Vec(vocab=12, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5Wogn-wwfX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "568b1c87-0234-4432-d769-5f8ea7c7f369"
      },
      "source": [
        "model.vector_size"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsMUf3A7wtOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e3a1d149-ab3d-43ca-9f34-02a990cccab0"
      },
      "source": [
        "model.wv.vocab"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ariana': <gensim.models.keyedvectors.Vocab at 0x7fd79a48c6d8>,\n",
              " 'Grande': <gensim.models.keyedvectors.Vocab at 0x7fd79a48cb38>,\n",
              " 'She': <gensim.models.keyedvectors.Vocab at 0x7fd79a49f358>,\n",
              " 'a': <gensim.models.keyedvectors.Vocab at 0x7fd79a48ce48>,\n",
              " 'been': <gensim.models.keyedvectors.Vocab at 0x7fd79a49f470>,\n",
              " 'for': <gensim.models.keyedvectors.Vocab at 0x7fd79a49f518>,\n",
              " 'great': <gensim.models.keyedvectors.Vocab at 0x7fd79a49f588>,\n",
              " 'has': <gensim.models.keyedvectors.Vocab at 0x7fd79a49f3c8>,\n",
              " 'is': <gensim.models.keyedvectors.Vocab at 0x7fd79a48cd68>,\n",
              " 'many': <gensim.models.keyedvectors.Vocab at 0x7fd79a49f4a8>,\n",
              " 'singer': <gensim.models.keyedvectors.Vocab at 0x7fd79a48cc18>,\n",
              " 'years': <gensim.models.keyedvectors.Vocab at 0x7fd79a49f5c0>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}